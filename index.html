<!-- import aframe and then ar.js with image tracking / location based features -->

<script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>
<script src="https://raw.githack.com/fcor/arjs-gestures/master/dist/gestures.js"></script>

<!-- style for the loader -->
<style>
    .arjs-loader {
        height: 100%;
        width: 100%;
        position: absolute;
        top: 0;
        left: 0;
        background-color: rgba(0, 0, 0, 0.8);
        z-index: 9999;
        display: flex;
        justify-content: center;
        align-items: center;
    }

    .arjs-loader div {
        text-align: center;
        font-size: 1.25em;
        color: white;
    }
    body {
          margin: 0px;
          overflow: hidden;
        }
</style>

<body style="margin : 0px; overflow: hidden;">
    <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
    <div class="arjs-loader">
        <div>Loading, please wait...</div>
    </div>


    <!-- a-frame scene -->
    <a-scene 
             vr-mode-ui="enabled: false;" 
             renderer="logarithmicDepthBuffer: true;" 
             embedded
             arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"
             gesture-detector
             id="scene">
        <!-- a-nft is the anchor that defines an Image Tracking entity -->
        <!-- on 'url' use the path to the Image Descriptors created before. -->
        <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
        <a-nft type="nft" url="https://vasilikichatzigeorgiou.github.io/image-tracking-ar-tutorial/assets/Earth" smooth="true" smoothCount="10" smoothTolerance=".01"
            smoothThreshold="5">
            <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
            <!--<a-entity gltf-model="./assets/earth/scene.gltf" 
                      scale="0.5 0.5 0.5" 
                      position="50 150 0" 
                      class="clickable"
                      gesture-handler="minScale: 0.25; maxScale: 10" >
            </a-entity>-->
            <a-assets>
                <video id="10-second-short-music" autoplay loop="true" src="./assets/10-second-short-music.mp4"></video>
              </a-assets>

              <!-- Using the asset management system. -->
              <a-video src="#10-second-short-music" width="16" height="9" position="0 0 -20"></a-video>
        </a-nft>
        <!-- static camera that moves according to the device movemenents -->
        <a-entity camera></a-entity>
    </a-scene>
</body>
